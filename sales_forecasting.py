# -*- coding: utf-8 -*-
#"""sales_forecasting.ipynb
#
#Automatically generated by Colaboratory.
#
#Original file is located at
#    https://colab.research.google.com/drive/1I4RUScT_KbPUVMDrTMlA-nIYT8Gki6l1
#
### Problem Statement
#
#[Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) competition on Kaggle:
#
#> Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. 
#>
#>
#> With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the "Sales" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.
#>
#> Data here: https://www.kaggle.com/c/rossmann-store-sales/data
#
### Downloading the Data
#"""

import opendatasets as od
od.download("https://www.kaggle.com/c/rossmann-store-sales/data")

import os
os.listdir('rossmann-store-sales')

import pandas as pd

ross_df = pd.read_csv('./rossmann-store-sales/train.csv', low_memory=False)
store_df = pd.read_csv('./rossmann-store-sales/store.csv')
test_df = pd.read_csv('./rossmann-store-sales/test.csv')
submission_df = pd.read_csv('./rossmann-store-sales/sample_submission.csv')

#"""> 'low_memory=False' is used to prevent this warning:
#>
#>
#> "c:\Users\acayt\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3457: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.
#  exec(code_obj, self.user_global_ns, self.user_ns)"
#"""

#ross_df

#test_df

#store_df

#"""Merging data from store_df to train and test dataframes:"""

merged_df = ross_df.merge(store_df, how='left', on='Store')
merged_test_df = test_df.merge(store_df, how='left', on='Store')

#merged_df

#"""## EDA"""

merged_df.info()

import matplotlib.pyplot as plt
import seaborn as sns

plt.title('No. of Rows per Year')
sns.countplot(x=pd.to_datetime(merged_df.Date).dt.year)

merged_df.corr()

crm = merged_df.corr()
plt.figure(figsize = (25, 25))
sns.heatmap(crm, annot = True)

#"""## Preprocessing and FE
#
#> `Date` column can be used to extract different parts of the date/day and what they symbolize <br>
#> such as `Date`, `Day`, `Month`, `Year` etc
#"""

def split_date(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df['Year'] = df.Date.dt.year
    df['Month'] = df.Date.dt.month
    df['Day'] = df.Date.dt.day
    df['WeekOfYear'] = df.Date.dt.isocalendar().week

split_date(merged_df)
split_date(merged_test_df)

#"""> `CompetitionOpenSince[Month/Year]` columns from `store_df` to compute the number of months for which a competitor has been open near the store."""

def comp_months(df):
    df['CompetitionOpen'] = 12 * (df.Year - df.CompetitionOpenSinceYear) + (df.Month - df.CompetitionOpenSinceMonth)
    df['CompetitionOpen'] = df['CompetitionOpen'].map(lambda x: 0 if x < 0 else x).fillna(0)

comp_months(merged_df)
comp_months(merged_test_df)

merged_df[['Date', 'CompetitionDistance', 'CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth', 'CompetitionOpen']].sample(20)

merged_df[merged_df.Open == 0].Sales.value_counts()

#"""> Sales are 0 whenever the store is closed - general observation, supported by the data as well. <br>
#> This can be hardcoded by dropping all the rows where the store is closed
#"""

merged_df = merged_df[merged_df.Open == 1].copy()

merged_df

#"""> Some additional columns can also be engineered to indicate how long a store has been running `Promo2` and whether a new round of `Promo2` starts in the current month."""

def check_promo_month(row):
    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',              
                 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}
    try:
        months = (row['PromoInterval'] or '').split(',')
        if row['Promo2Open'] and month2str[row['Month']] in months:
            return 1
        else:
            return 0
    except Exception:
        return 0

def promo_cols(df):
    # Months since Promo2 was open
    df['Promo2Open'] = 12 * (df.Year - df.Promo2SinceYear) +  (df.WeekOfYear - df.Promo2SinceWeek)*7/30.5
    df['Promo2Open'] = df['Promo2Open'].map(lambda x: 0 if x < 0 else x).fillna(0) * df['Promo2']
    # Whether a new round of promotions was started in the current month
    df['IsPromo2Month'] = df.apply(check_promo_month, axis=1) * df['Promo2']

promo_cols(merged_df)
promo_cols(merged_test_df)

merged_df[['Date', 'Promo2', 'Promo2SinceYear', 'Promo2SinceWeek', 'PromoInterval', 'Promo2Open', 'IsPromo2Month']].sample(20)

#"""### Selecting Input and Target attributes"""

merged_df.columns

input_cols = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 
              'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen', 
              'Day', 'Month', 'Year', 'WeekOfYear',  'Promo2', 
              'Promo2Open', 'IsPromo2Month']
target_col = 'Sales'

inputs = merged_df[input_cols].copy()
targets = merged_df[target_col].copy()

test_inputs = merged_test_df[input_cols].copy()

numeric_cols = ['Store', 'Promo', 'SchoolHoliday', 
              'CompetitionDistance', 'CompetitionOpen', 'Promo2', 'Promo2Open', 'IsPromo2Month',
              'Day', 'Month', 'Year', 'WeekOfYear',  ]
categorical_cols = ['DayOfWeek', 'StateHoliday', 'StoreType', 'Assortment']

#"""### Imputing Missing data"""

inputs[numeric_cols].isna().sum()

#"""> `CompetitionDistance` is the only missing value. <br>
#> It can fill it with the highest value to indicate that competition is too far away to be even recorded.
#"""

max_distance = inputs.CompetitionDistance.max()

inputs['CompetitionDistance'].fillna(max_distance, inplace=True)
test_inputs['CompetitionDistance'].fillna(max_distance, inplace=True)

#"""### Scaling Numeric data"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler().fit(inputs[numeric_cols])
inputs[numeric_cols] = scaler.transform(inputs[numeric_cols])

test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])

#"""### Encoding Categorical data"""

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(inputs[categorical_cols])
encoded_cols = list(encoder.get_feature_names_out(categorical_cols))

encoded_cols

inputs[encoded_cols] = encoder.transform(inputs[categorical_cols])
test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])

X = inputs[numeric_cols + encoded_cols]
X_test = test_inputs[numeric_cols + encoded_cols]

X.shape

#"""## Model Training"""

import tensorflow as tf

neural_net = tf.keras.Sequential()

#"""> Input Layer:"""

neural_net.add(tf.keras.layers.Dense(128, kernel_initializer='normal',input_dim = X.shape[1], activation='relu'))

#"""> Hidden Layers:"""

neural_net.add(tf.keras.layers.Dense(256, kernel_initializer='normal',activation='relu'))
#neural_net.add(tf.keras.layers.Dropout(0.2))
neural_net.add(tf.keras.layers.Dense(256, kernel_initializer='normal',activation='relu'))
neural_net.add(tf.keras.layers.Dense(512, kernel_initializer='normal',activation='relu'))
neural_net.add(tf.keras.layers.Dense(256, kernel_initializer='normal',activation='relu'))

#"""> Output Layer:"""

neural_net.add(tf.keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))

#"""> Compiling the model"""

neural_net.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
neural_net.summary()

neural_net.fit(X, targets, epochs=5, batch_size=32, validation_split = 0.2)

#"""## Testing & Submission"""

def make_submission(prediction):
  my_submission = pd.DataFrame({'Id':merged_test_df.Id,'Sales':prediction})
  my_submission.to_csv('submission.csv',index=False)
  print('A submission file has been made')

predictions = neural_net.predict(X_test)
make_submission(predictions[:,0])

